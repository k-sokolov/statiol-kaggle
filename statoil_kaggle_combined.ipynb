{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score, train_test_split\n",
    "from skimage.filters import gaussian\n",
    "from functools import reduce\n",
    "import keras\n",
    "from keras.layers import Dense, Input, BatchNormalization, Concatenate, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.py functions\n",
    "def transform(df):\n",
    "    band_1 = np.array([np.array(row).reshape(75, 75) for row in df['band_1']])\n",
    "    band_2 = np.array([np.array(row).reshape(75, 75) for row in df['band_2']])\n",
    "    band_3 = band_1 * band_2\n",
    "    band_4 = gaussian(band_1 + band_2 / 2)\n",
    "    \n",
    "    x = np.concatenate([band_2[:, :, :, np.newaxis], band_1[:, :, :, np.newaxis],\\\n",
    "                       band_3[:, :, :, np.newaxis], band_4[:, :, :, np.newaxis]], axis=-1)\n",
    "    angle = np.array([np.array(row) for row in df['inc_angle']])\n",
    "    \n",
    "    return x, angle \n",
    "\n",
    "    \n",
    "def augment(images):\n",
    "    image_mirror_lr = []\n",
    "    image_mirror_ud = []\n",
    "    for i in range(0,images.shape[0]):\n",
    "        band_1 = images[i,:,:,0]\n",
    "        band_2 = images[i,:,:,1]\n",
    "        band_3 = images[i,:,:,2]\n",
    "        band_4 = images[i,:,:,3]\n",
    "\n",
    "        # mirror left-right\n",
    "        band_1_mirror_lr = np.flip(band_1, 0)\n",
    "        band_2_mirror_lr = np.flip(band_2, 0)\n",
    "        band_3_mirror_lr = np.flip(band_3, 0)\n",
    "        band_4_mirror_lr = np.flip(band_4, 0)\n",
    "        image_mirror_lr.append(np.stack((band_1_mirror_lr, band_2_mirror_lr, band_3_mirror_lr, band_4_mirror_lr), axis=-1))\n",
    "        \n",
    "        # mirror up-down\n",
    "        band_1_mirror_ud = np.flip(band_1, 1)\n",
    "        band_2_mirror_ud = np.flip(band_2, 1)\n",
    "        band_3_mirror_ud = np.flip(band_3, 1)\n",
    "        band_4_mirror_ud = np.flip(band_4, 1)\n",
    "        image_mirror_ud.append(np.stack((band_1_mirror_ud, band_2_mirror_ud, band_3_mirror_ud, band_4_mirror_ud), axis=-1))\n",
    "        \n",
    "    mirrorlr = np.array(image_mirror_lr)\n",
    "    mirrorud = np.array(image_mirror_ud)\n",
    "    images = np.concatenate((images, mirrorlr, mirrorud))\n",
    "    return images\n",
    "\n",
    "    \n",
    "def split_data(imgs, angls, lbls, seed):\n",
    "    rs = ShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "    tr_idx, val_idx = next(rs.split(imgs))\n",
    "    train_im_1, train_im_2, train_ang, train_y = imgs[tr_idx, :, :, :2], imgs[tr_idx, :, :, 2:], angls[tr_idx], lbls[tr_idx]\n",
    "    val_im_1, val_im_2, val_ang, val_y = imgs[val_idx, :, :, :2], imgs[val_idx, :, :, 2:], angls[val_idx], lbls[val_idx]\n",
    "    \n",
    "    return [train_im_1, train_im_2, train_ang, train_y], [val_im_1, val_im_2, val_ang, val_y]\n",
    "    \n",
    "#def make_gen(x_data_img, x_data_angle, y_data, batch_size):\n",
    "#    num_images = len(x_data_img)\n",
    "#\n",
    "#    if len(y_data) == 1:\n",
    "#        y_data = y_data[0]\n",
    "\n",
    "#    while True:\n",
    "#        idx1 = np.random.randint(0, num_images, batch_size)\n",
    "#        #idx2 = np.random.randint(0, num_images, batch_size)\n",
    "#\n",
    "#        batch_x = [x_data_img[idx1, 2, :, :, :],\\\n",
    "#                   x_data_angle[idx1]]\n",
    "#        \n",
    "#        batch_y = y_data[idx1]\n",
    "#\n",
    "#        yield batch_x, batch_y\n",
    "        \n",
    "def prepare_data_train(filename='train.json'):\n",
    "    train = pd.read_json(filename)\n",
    "    train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "    train_X, angles = transform(train)\n",
    "    train_y = np.array(train['is_iceberg'])\n",
    "    train_X = augment(train_X)\n",
    "    train_y = np.concatenate((train_y, train_y, train_y))\n",
    "    angles = np.concatenate((angles, angles, angles))\n",
    "\n",
    "    return train_X, angles, train_y\n",
    "    \n",
    "def prepare_data_test(filename='test.json'):\n",
    "    test = pd.read_json(filename)\n",
    "    test.inc_angle = test.inc_angle.fillna(0)\n",
    "    ids = test['id']\n",
    "    test_X, angles = transform(test)\n",
    "\n",
    "    return test_X[:, :, :, :2], test_X[:, :, :, 2:], angles, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#network.py\n",
    "def make_model():\n",
    "    inp_img_1 = Input(shape=(75, 75, 2), name='input1_img')\n",
    "    inp_img_2 = Input(shape=(75, 75, 2), name='input2_img')\n",
    "\n",
    "    inp_angle = Input(shape=(1,), name='input_angle')\n",
    "    \n",
    "    C1, C2, C3 = 32, 64, 30\n",
    "    \n",
    "    img_flow_tpl1 = [BatchNormalization(),\n",
    "                     Conv2D(C1, (3, 3), activation='relu', padding='valid'),\n",
    "                     Conv2D(C1, (3, 3), activation='relu', padding='valid'),\n",
    "                     MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "                     Dropout(DROPOUT_RATE),\n",
    "\n",
    "                     Conv2D(C2, (3, 3), activation='relu', padding='valid'),\n",
    "                     Conv2D(C2, (3, 3), activation='relu', padding='valid'),\n",
    "                     MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "                     Dropout(DROPOUT_RATE),\n",
    "                     \n",
    "                     Flatten()\n",
    "                     ]\n",
    "\n",
    "    angle_flow_tpl1 = [BatchNormalization(),\n",
    "                      Dense(16, activation='relu')\n",
    "                     ]\n",
    "    \n",
    "    img_flow_tpl2 = [BatchNormalization(),\n",
    "                     Conv2D(C1, (3, 3), activation='relu', padding='valid'),\n",
    "                     Conv2D(C1, (3, 3), activation='relu', padding='valid'),\n",
    "                     MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "                     Dropout(DROPOUT_RATE),\n",
    "\n",
    "                     Conv2D(C2, (3, 3), activation='relu', padding='valid'),\n",
    "                     Conv2D(C2, (3, 3), activation='relu', padding='valid'),\n",
    "                     MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "                     Dropout(DROPOUT_RATE),\n",
    "                     \n",
    "                     Flatten()\n",
    "                     ]\n",
    "                     \n",
    "    angle_flow_tpl2 = [BatchNormalization(),\n",
    "                      Dense(16, activation='relu')\n",
    "                     ]\n",
    "\n",
    "    img_1_flow = [inp_img_1] + img_flow_tpl1\n",
    "    img_2_flow = [inp_img_2] + img_flow_tpl2\n",
    "\n",
    "    x1 = reduce(lambda x, y: y(x), img_1_flow)\n",
    "    x2 = reduce(lambda x, y: y(x), img_2_flow)\n",
    "\n",
    "    angle_1_flow = [inp_angle] + angle_flow_tpl1\n",
    "    angle_2_flow = [inp_angle] + angle_flow_tpl2\n",
    "\n",
    "\n",
    "    x1_angle = reduce(lambda x, y: y(x), angle_1_flow)\n",
    "    x2_angle = reduce(lambda x, y: y(x), angle_2_flow)\n",
    "\n",
    "\n",
    "\n",
    "    x1 = Concatenate(name='features1')([x1, x1_angle])\n",
    "    x2 = Concatenate(name='features2')([x2, x2_angle])\n",
    "\n",
    "    x = Concatenate()([x1, x2])\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    x = Dropout(DROPOUT_RATE)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model([inp_img_1, inp_img_2, inp_angle], out)\n",
    "\n",
    "    adam = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\t\n",
    "DROPOUT_RATE = 0.3\n",
    "N_FOLDS = 1\n",
    "\n",
    "def main():\n",
    "    train_X, angles, train_y = prepare_data_train()\n",
    "    for f in range(N_FOLDS):\n",
    "        tr, val  = split_data(train_X, angles, train_y, f)\n",
    "\n",
    "        tr_x, val_x = tr[:-1], val[:-1]\n",
    "        tr_y, val_y = tr[-1], val[-1]\n",
    "\n",
    "        model = make_model()\n",
    "        model.summary()\n",
    "        model.fit(tr_x, tr_y,\n",
    "          batch_size=24,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(val_x, val_y))\n",
    "\n",
    "        model.save('net' + str(f))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load model and generate predictions, predict.py\n",
    "\n",
    "def main():\n",
    "    test_img_1, test_img_2, angles, ids = prepare_data_test()\n",
    "    model = load_model('net0')\n",
    "    out = model.predict(x=[test_img_1, test_img_2, angles]).flatten()\n",
    "    d = {'id' : ids, 'is_iceberg' : out}\n",
    "\n",
    "    pd.DataFrame(data=d).to_csv('out.csv', index=False)   \n",
    "    print('Done')\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
